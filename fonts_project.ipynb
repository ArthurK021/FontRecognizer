{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fonts_project.ipynb","provenance":[],"machine_shape":"hm","collapsed_sections":[],"mount_file_id":"1EAGXHEOrjP8pudkWJXljxshh1ZEHP3VV","authorship_tag":"ABX9TyOYI7uvhaDP4D8JfdX7jhqI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"yA8I6Z5Cm3TW","executionInfo":{"status":"ok","timestamp":1661361537476,"user_tz":-180,"elapsed":3202,"user":{"displayName":"Arthur Kogan","userId":"13783745692622805536"}}},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","import h5py\n","from PIL import Image\n","import numpy as np\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","from torchvision.models.resnet import resnet50\n","import pandas as pd\n","from torch.utils.data import Subset\n","import torch.optim as optim\n","import torch.nn as nn\n","from tqdm import tqdm"]},{"cell_type":"code","source":["class CharDataset(Dataset):\n","    def __init__(self, transform=None, include_font_label=True,include_char_label=False, h5_file_path='/content/drive/MyDrive/SynthText.h5'):\n","        all_text = ''\n","        self.transform = transform\n","        self.db = h5py.File(h5_file_path, 'r')\n","        im_names = list(self.db['data'].keys())\n","        self.chars_files_names, self.char_index_within_file = [], []\n","        for image_filename in im_names:\n","            num_of_characters = self.db['data'][image_filename].attrs['charBB'].shape[-1]\n","            text = self.db['data'][image_filename].attrs['txt']\n","            actual_text = ''.join([word.decode('UTF-8') for word in text])\n","            all_text += actual_text\n","            for char_index in range(num_of_characters):\n","                self.chars_files_names.append(image_filename)\n","                self.char_index_within_file.append(char_index)\n","        self.fonts_labels = ['Raleway','Open Sans','Ubuntu Mono','Russo One','Alex Brush','Michroma','Roboto']\n","        self.include_font_label = include_font_label\n","        self.include_char_label = include_char_label\n","        self.all_text = all_text\n","        \n","    def __getitem__(self, idx):\n","        \n","        image_filename = self.chars_files_names[idx]\n","        char_image_index = self.char_index_within_file[idx]\n","        img = self.db['data'][image_filename][:]\n","        character_bounding_box = self.db['data'][image_filename].attrs['charBB'][:, :, char_image_index]\n","        x0 = min(character_bounding_box[0])\n","        x1 = max(character_bounding_box[0])\n","        y0 = min(character_bounding_box[1])\n","        y1 = max(character_bounding_box[1])\n","        (x0,y0,x1,y1) = (round(x0),round(y0),round(x1),round(y1))\n","        y_max,x_max,_ = img.shape\n","        x0 = min(x_max,max(0,x0))\n","        x1 = min(x_max, max(0, x1))\n","        y0 = min(y_max, max(0, y0))\n","        y1 = min(y_max, max(0, y1))\n","        cut_image = img[y0:y1, x0:x1, :]\n","        pil_image = Image.fromarray(cut_image.astype(np.uint8))\n","        if self.transform is not None:\n","            pil_image = self.transform(pil_image)\n","        if self.include_font_label:\n","            font_name = self.db['data'][image_filename].attrs['font'][char_image_index].decode('UTF-8')\n","            font_label = self.fonts_labels.index(font_name)\n","            return pil_image,font_label\n","        if not self.include_char_label:\n","            raise ValueError('One of include labels (char or font) has to be True')\n","        data_dict = {'image': pil_image, 'char': self.all_text[idx], 'file_name': self.chars_files_names[idx]}\n","        try:\n","            font_name = self.db['data'][image_filename].attrs['font'][char_image_index].decode('UTF-8')\n","            font_label = self.fonts_labels.index(font_name)\n","            data_dict['font_label'] = font_label\n","        except:\n","            pass\n","        return data_dict\n","        \n","            \n","        return pil_image\n","    def __len__(self):\n","        return len(self.char_index_within_file)"],"metadata":{"id":"0e3gurqrm6AJ","executionInfo":{"status":"ok","timestamp":1661361539468,"user_tz":-180,"elapsed":284,"user":{"displayName":"Arthur Kogan","userId":"13783745692622805536"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def train_net(net,l2_regularization=0,learning_rate=10**-4,fold_index=0,epochs=90):\n","\n","\n","    batch_size = 8\n","    image_size = (224,224)\n","    device = 'cuda:0'\n","    transform = transforms.Compose(\n","        [transforms.Resize(image_size),transforms.ToTensor(),\n","         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),transforms.RandomRotation(degrees=(-10,10))])\n","    \n","    char_data = CharDataset(transform=transform)\n","    \n","    \n","    \n","    \n","    dataset_size = len(char_data)\n","    validation_size = round(dataset_size*0.2)\n","    validation_examples_indices = [x for x in range(fold_index*validation_size,(fold_index+1)*validation_size)]\n","    train_set = Subset(char_data, [x for x in range(0,dataset_size) if x not in validation_examples_indices])\n","    valid_set = Subset(char_data, [x for x in range(0,dataset_size) if x in validation_examples_indices])\n","    \n","    \n","    trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n","                                              shuffle=True, num_workers=8)\n","    validation_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size,\n","                                              shuffle=False, num_workers=2)\n","    \n","    \n","    criterion = nn.CrossEntropyLoss()\n","    \n","    \n","    @torch.no_grad()\n","    def get_accuracy_on_validation(net=net, dataLoader=validation_loader):\n","        net.eval()\n","        seen_examples = 0.0\n","        num_correct_examples = 0\n","        for (i, data) in enumerate(dataLoader, 0):\n","            inputs, labels = data\n","            inputs , labels = inputs.to(device) , labels.to(device)\n","            outputs = net(inputs)\n","            num_correct_examples += (outputs.argmax(dim=1) == labels).sum().item()\n","            seen_examples += inputs.size()[0]\n","        net.train(True)\n","        return num_correct_examples/seen_examples\n","    \n","    \n","    \n","    optimizer = optim.Adam(net.parameters(), lr=learning_rate,weight_decay=l2_regularization)\n","    \n","    best_validation = 0.0\n","    for epoch in range(epochs):  # loop over the dataset multiple times\n","        print(f'at epoch {epoch}')\n","        running_loss = 0.0\n","        for i, data in enumerate(tqdm(trainloader), 0):\n","            # get the inputs; data is a list of [inputs, labels]\n","            inputs, labels = data\n","            inputs, labels = inputs.to(device), labels.to(device) #Switch to GPU!\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","    \n","            # forward + backward + optimize\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward() #calculate the gradient\n","            optimizer.step() #update the net's parameters\n","    \n","            # print statistics\n","            running_loss += loss.item()\n","            if i % 2000 == 1999:    # print every 2000 mini-batches\n","                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n","                running_loss = 0.0\n","                accuracy_on_validation = get_accuracy_on_validation()\n","                if best_validation<accuracy_on_validation:\n","                    best_validation = accuracy_on_validation\n","                    torch.save(net.state_dict(),f'{best_validation}_fold{fold_index}.net')\n","                print(f'accuracy on validation is {accuracy_on_validation}')\n","    \n","    print('Finished Training')\n","    return get_accuracy_on_validation()"],"metadata":{"id":"M8mze2wO59L4","executionInfo":{"status":"ok","timestamp":1661361541322,"user_tz":-180,"elapsed":704,"user":{"displayName":"Arthur Kogan","userId":"13783745692622805536"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["for fold_index in range(0,5):\n","  net = resnet50(pretrained=True,num_classes=1000).to(device)\n","  train_net(net=net,l2_regularization=10**-12,learning_rate=10**-4,epochs=20,fold_index=fold_index)"],"metadata":{"id":"ipcx9PwD6ERh","colab":{"base_uri":"https://localhost:8080/","height":435},"executionInfo":{"status":"error","timestamp":1661361588912,"user_tz":-180,"elapsed":19032,"user":{"displayName":"Arthur Kogan","userId":"13783745692622805536"}},"outputId":"ce0c20c3-89bd-47f3-a45d-3dabb0e73e34"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["at epoch 0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/2820 [00:05<?, ?it/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-26b1b019e7ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml2_regularization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfold_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-829ac79be5a6>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(net, l2_regularization, learning_rate, fold_index, epochs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#calculate the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"]}]},{"cell_type":"code","source":["our_result = pd.DataFrame(columns=['image','char','Raleway','Open Sans','Roboto','Ubuntu Mono','Michroma','Alex Brush','Russo One'])\n","device = 'cuda:0'\n","image_size = (224,224)"],"metadata":{"id":"DM04ohqOSWHU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose(\n","    [transforms.Resize(image_size),transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","test_char_data = CharDataset(transform=transform, include_font_label=False,include_char_label=True,h5_file_path='/content/drive/MyDrive/SynthText_test.h5')\n","test_load = torch.utils.data.DataLoader(test_char_data, batch_size=1,\n","                                          shuffle=False, num_workers=8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mk5cpTq-S4ix","executionInfo":{"status":"ok","timestamp":1642461445917,"user_tz":-120,"elapsed":10155,"user":{"displayName":"Arthur Kogan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13783745692622805536"}},"outputId":"9f5ee15d-5359-435f-814c-a8c0dadf04c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","from torchvision.models.resnet import resnet50\n","import pandas as pd\n","from torch.utils.data import Subset\n","import torch.optim as optim\n","import torch.nn as nn\n","from tqdm import tqdm\n","import os\n","our_result = pd.DataFrame(columns=['image','char','Raleway','Open Sans','Roboto','Ubuntu Mono','Michroma','Alex Brush','Russo One'])\n","device = 'cuda:0'\n","NETS_FOLDER = '/content/drive/MyDrive'\n","nets_filenames = [x for x in os.listdir(NETS_FOLDER) if x[-len('.net'):]=='.net']\n","image_size = (224,224)\n","\n","nets=[]\n","print(f'nets available are {nets_filenames}')\n","for net_filename in nets_filenames:\n","    net = resnet50(pretrained=True,num_classes=1000).to(device)\n","    net.load_state_dict(torch.load(os.path.join(NETS_FOLDER,net_filename)))\n","    net.eval()\n","    nets.append(net)\n","\n","\n","\n","transform = transforms.Compose(\n","    [transforms.Resize(image_size),transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","test_char_data = CharDataset(transform=transform, include_font_label=False,include_char_label=True,h5_file_path='/content/drive/MyDrive/SynthText_test.h5')\n","test_load = torch.utils.data.DataLoader(test_char_data, batch_size=1,\n","                                          shuffle=False, num_workers=8)\n","\n","@torch.no_grad()\n","def save_test_estimation(dataLoader=test_load):\n","    global our_result\n","    seen_examples = 0.0\n","    num_correct_examples = 0\n","    for (i, data) in enumerate(tqdm(dataLoader), 0):\n","        inputs, image_filename,char = data['image'],data['file_name'],data['char']\n","        labels = data['font_label'] if 'font_label' in data else None\n","        inputs  = inputs.to(device)\n","        probabilities = torch.zeros(1,7).to(device)\n","        for net in nets:\n","            outputs = net(inputs)[:,0:7]\n","            probabilities += torch.nn.Softmax(dim=1)(outputs)\n","        chosen_font_index = probabilities.argmax(dim=1).item()\n","        chosen_font_name = test_char_data.fonts_labels[chosen_font_index]\n","        save_data = {'image':image_filename[0], 'char':char[0], 'Raleway':0, 'Open Sans':0, 'Roboto':0, 'Ubuntu Mono':0, 'Michroma':0, 'Alex Brush':0, 'Russo One':0}\n","        save_data[chosen_font_name] = 1\n","        our_result = our_result.append(save_data,ignore_index=True)\n","        if labels is not None:\n","            labels = labels.to(device)\n","            num_correct_examples += (probabilities.argmax(dim=1) == labels).sum().item()\n","        seen_examples += inputs.size()[0]\n","        #print(num_correct_examples/seen_examples*100)\n","    return num_correct_examples/seen_examples\n","save_test_estimation()\n","our_result.to_csv('/content/drive/MyDrive/our_result_on_training_set.csv')\n","\n","for fold_index in range(0,5):\n","  net = resnet50(pretrained=True,num_classes=1000).to(device)\n","  train_net(net=net,l2_regularization=10**-12,learning_rate=10**-4,epochs=50,fold_index=fold_index)\n"],"metadata":{"id":"e_XfkrZNT8Dx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cat /content/drive/MyDrive/our_result_on_test_set.csv |wc -l"],"metadata":{"id":"O6mRWIboT_7t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642515062368,"user_tz":-120,"elapsed":1099,"user":{"displayName":"Arthur Kogan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13783745692622805536"}},"outputId":"5b6bfb6a-c98c-4d13-d147-b5672de92ccb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["56166\n"]}]}]}